<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Example</title>
  <style>
    html,
    body {
      width: 100%;
      height: 100%;
      background-color: #ffffff;
      margin: 0;
      padding: 0;
      overflow: hidden;
    }
  </style>
</head>
<body>
  <video id="_webcam" style="display: none;" playsinline></video>
  <canvas id="_imageData"></canvas>
  <img id="JewelleryToTry" src="images/jewelleryEdited01.png"/>
  <script src="./js/brfv5/brfv5_js_tk240320_v5.1.5_trial_no_modules.js"></script>
  <script>
    const queryString = new URLSearchParams(window.location.search);
    const imageurl= queryString.get('imageurl');
    const imagetype = "EARRING";//queryString.get('imagetype');
    var loadingFlag = true;
    const THRESHOLD_FOR_EARING_DETECTION = 0.28;
    const THRESHOLD_FOR_EARING_PLACEMENT = 5;
    const THRESHOLD_FOR_FACE_TILT = 0.25;
    const VERBOSE = true;
  </script>
  <script>
    // Set the BRFv5 library name here, also set your own appId for reference.
    const _libraryName = 'brfv5_js_tk240320_v5.1.5_trial.brfv5'
    const _appId = 'brfv5.browser.minimal.nomodules' // (mandatory): 8 to 64 characters, a-z . 0-9 allowed
    const brfv5 = {} // The library namespace.
    // References to the video and canvas.
    const _webcam = document.getElementById('_webcam')
    const _imageData = document.getElementById('_imageData')
    // Those variables will be retrieved from the stream and the library.
    let _brfv5Manager = null
    let _brfv5Config = null
    let _width = 0
    let _height = 0
    // loadBRFv5Model and openCamera are being done simultaneously thanks to Promises. Both call
    // configureTracking which only gets executed once both Promises were successful. Once configured
    // trackFaces will do the tracking work and draw the results.
    const loadBRFv5Model = (modelName, numChunksToLoad, pathToModels = '', appId = null, onProgress = null) => {
      console.log('loadBRFv5Model')
      if (!modelName) {
        throw 'Please provide a modelName.'
      }
      return new Promise((resolve, reject) => {
        if (_brfv5Manager && _brfv5Config) {
          resolve({
            brfv5Manager: _brfv5Manager,
            brfv5Config: _brfv5Config
          })
        } else {
          try {
            brfv5.appId = appId ? appId : _appId
            brfv5.binaryLocation = pathToModels + _libraryName
            brfv5.modelLocation = pathToModels + modelName + '_c'
            brfv5.modelChunks = numChunksToLoad // 4, 6, 8
            brfv5.binaryProgress = onProgress
            brfv5.binaryError = (e) => {
              reject(e)
            }
            brfv5.onInit = (brfv5Manager, brfv5Config) => {
              _brfv5Manager = brfv5Manager
              _brfv5Config = brfv5Config
              resolve({
                brfv5Manager: _brfv5Manager,
                brfv5Config: _brfv5Config
              })
            }
            brfv5Module(brfv5)
          } catch (e) {
            reject(e)
          }
        }
      })
    }
    const openCamera = () => {
      console.log('openCamera')
      return new Promise((resolve, reject) => {
        window.navigator.mediaDevices.getUserMedia({
            video: {
              width: 640,
              height: 480,
              frameRate: 30,
              facingMode: 'user'
            }
          })
          .then((mediaStream) => {
            _webcam.srcObject = mediaStream
            _webcam.play().then(() => {
              resolve({
                width: _webcam.videoWidth,
                height: _webcam.videoHeight
              })
            }).catch((e) => {
              reject(e)
            })
          }).catch((e) => {
            reject(e)
          })
      })
    }
    const configureTracking = () => {
      if (_brfv5Config !== null && _width > 0) {
        // Camera stream and BRFv5 are ready. Now configure. Internal defaults are set for a 640x480 resolution.
        // So the following isn't really necessary.
        const brfv5Config = _brfv5Config
        const imageWidth = _width
        const imageHeight = _height
        const inputSize = imageWidth > imageHeight ? imageHeight : imageWidth
        // Setup image data dimensions
        brfv5Config.imageConfig.inputWidth = imageWidth
        brfv5Config.imageConfig.inputHeight = imageHeight
        const sizeFactor = inputSize / 480.0
        // Set face detection region of interest and parameters scaled to the image base size.
        brfv5Config.faceDetectionConfig.regionOfInterest.setTo(0, 0, imageWidth, imageHeight)
        brfv5Config.faceDetectionConfig.minFaceSize = 144 * sizeFactor
        brfv5Config.faceDetectionConfig.maxFaceSize = 480 * sizeFactor
        if (imageWidth < imageHeight) {
          // Portrait mode: probably smartphone, faces tend to be closer to the camera, processing time is an issue,
          // so save a bit of time and increase minFaceSize.
          brfv5Config.faceDetectionConfig.minFaceSize = 240 * sizeFactor
        }
        // Set face tracking region of interest and parameters scaled to the image base size.
        brfv5Config.faceTrackingConfig.regionOfInterest.setTo(0, 0, imageWidth, imageHeight)
        brfv5Config.faceTrackingConfig.minFaceScaleStart = 50.0 * sizeFactor
        brfv5Config.faceTrackingConfig.maxFaceScaleStart = 320.0 * sizeFactor
        brfv5Config.faceTrackingConfig.minFaceScaleReset = 35.0 * sizeFactor
        brfv5Config.faceTrackingConfig.maxFaceScaleReset = 420.0 * sizeFactor
        brfv5Config.faceTrackingConfig.confidenceThresholdReset = 0.001
        brfv5Config.faceTrackingConfig.enableStabilizer = true
        brfv5Config.faceTrackingConfig.maxRotationXReset = 35.0
        brfv5Config.faceTrackingConfig.maxRotationYReset = 45.0
        brfv5Config.faceTrackingConfig.maxRotationZReset = 34.0
        brfv5Config.faceTrackingConfig.numTrackingPasses = 3
        brfv5Config.faceTrackingConfig.enableFreeRotation = true
        brfv5Config.faceTrackingConfig.maxRotationZReset = 999.0
        brfv5Config.faceTrackingConfig.numFacesToTrack = 1
        brfv5Config.enableFaceTracking = true
        //console.log('configureTracking:', _brfv5Config)
        _brfv5Manager.configure(_brfv5Config)
        trackFaces()
      }
    }
    const trackFaces = () => {
      if (!_brfv5Manager || !_brfv5Config || !_imageData) {
        return
      }
      const ctx = _imageData.getContext('2d')
      ctx.setTransform(-1.0, 0, 0, 1, _width, 0) // A virtual mirror should be... mirrored
      ctx.drawImage(_webcam, 0, 0, _width, _height)
      ctx.setTransform(1.0, 0, 0, 1, 0, 0) // unmirror to draw the results
      _brfv5Manager.update(ctx.getImageData(0, 0, _width, _height))
      let doDrawFaceDetection = !_brfv5Config.enableFaceTracking
      if (_brfv5Config.enableFaceTracking) {
        const sizeFactor = Math.min(_width, _height) / 480.0
        const faces = _brfv5Manager.getFaces()
        for (let i = 0; i < faces.length; i++) {
          const face = faces[i]
          if (face.state === brfv5.BRFv5State.FACE_TRACKING) {
            //drawRect(ctx, _brfv5Config.faceTrackingConfig.regionOfInterest, '#00a0ff', 2.0)
            //drawCircles(ctx, face.landmarks, '#00a0ff', 2.0 * sizeFactor)
            //drawRect(ctx, face.bounds, '#ffffff', 1.0)
            processLandmarks(ctx, face.landmarks, '#00a0ff', 2.0 * sizeFactor);
          }
        }
      }
      requestAnimationFrame(trackFaces)
    }
    openCamera().then(({
      width,
      height
    }) => {
      //console.log('openCamera: done: ' + width + 'x' + height)
      _width = width;
      _height = height;
      _imageData.width = _width
      _imageData.height = _height
      _imageData.style.width = "100vw";
      _imageData.style.height = "100vh";
      configureTracking()
    }).catch((e) => {
      if (e) {
        console.error('Camera failed: ', e)
      }
    })
    loadBRFv5Model('68l', 8, './js/brfv5/models/', _appId,
      (progress) => {
        ;//console.log(progress)
      }).then(({
      brfv5Manager,
      brfv5Config
    }) => {
      //console.log('loadBRFv5Model: done')
      _brfv5Manager = brfv5Manager
      _brfv5Config = brfv5Config
      configureTracking()
    }).catch((e) => {
      console.error('BRFv5 failed: ', e)
    })
    const drawCircles = (ctx, array, color, radius) => {
      ctx.strokeStyle = null
      ctx.fillStyle = getColor(color, 1.0)
      let _radius = radius || 2.0
      for (let i = 0; i < array.length; ++i) {
        ctx.beginPath()
        ctx.arc(array[i].x, array[i].y, _radius, 0, 2 * Math.PI)
        ctx.fill()
      }
    }
    const drawRect = (ctx, rect, color, lineWidth) => {
      ctx.strokeStyle = getColor(color, 1.0)
      ctx.fillStyle = null
      ctx.lineWidth = lineWidth || 1.0
      ctx.beginPath()
      ctx.rect(rect.x, rect.y, rect.width, rect.height)
      ctx.stroke()
    }
    const drawRects = (ctx, rects, color, lineWidth) => {
      ctx.strokeStyle = getColor(color, 1.0)
      ctx.fillStyle = null
      ctx.lineWidth = lineWidth || 1.0
      for (let i = 0; i < rects.length; ++i) {
        let rect = rects[i]
        ctx.beginPath()
        ctx.rect(rect.x, rect.y, rect.width, rect.height)
        ctx.stroke()
      }
    }

    const getColor = (color, alpha) => {
      const colorStr = color + ''
      if (colorStr.startsWith('rgb')) {
        return color
      }
      if (colorStr.startsWith('#')) {
        color = parseInt('0x' + colorStr.substr(1))
      }
      return 'rgb(' +
        (((color >> 16) & 0xff).toString(10)) + ', ' +
        (((color >> 8) & 0xff).toString(10)) + ', ' +
        (((color) & 0xff).toString(10)) + ', ' + alpha + ')'
    }
  </script>
<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->
<!--                                                                                                                                                           -->
<!--                                                                    EDIT THE FOLLOWING CODE                                                                -->
<!--                                                                                                                                                           -->
<!-- --------------------------------------------------------------------------------------------------------------------------------------------------------- -->
  <script>
	function processLandmarks(ctx, array, color, radius){
      const nose_point = array[30];
      const left_ear_point = array[2];
      const right_ear_point = array[14];
      const point_above_nose_point = array[29];

      // Initializing the Drawing Colors
      ctx.strokeStyle = null;
      ctx.fillStyle = getColor(color, 1.0);
      let _radius = radius || 2.0;

      if(VERBOSE == true){
        // Plotting the Nose Point
        ctx.fillStyle = "rgb(255,0,0)";
        ctx.beginPath();
        ctx.arc(nose_point.x, nose_point.y, _radius, 0, 2 * Math.PI);
        ctx.fill();

        // Plotting the Point Above Nose Point
        ctx.fillStyle = "rgb(255,0,255)";
        ctx.beginPath();
        ctx.arc(point_above_nose_point.x, point_above_nose_point.y, _radius, 0, 2 * Math.PI);
        ctx.fill();

        // Plotting the Left Ear Point
        ctx.fillStyle = "rgb(0,0,255)";
        ctx.beginPath();
        ctx.arc(left_ear_point.x, left_ear_point.y, _radius, 0, 2 * Math.PI);
        ctx.fill();

        // Plotting the Right Ear Point
        ctx.fillStyle = "rgb(0,0,255)";
        ctx.beginPath();
        ctx.arc(right_ear_point.x, right_ear_point.y, _radius, 0, 2 * Math.PI);
        ctx.fill();

        // Plotting the Line Connecting the Left and Right Ear Points
        ctx.strokeStyle = "rgb(0,255,0)";
        ctx.beginPath();
        ctx.moveTo(left_ear_point.x, left_ear_point.y);
        ctx.lineTo(right_ear_point.x, right_ear_point.y);
        ctx.stroke();
      }

      // Transforming the Plane Coordinates to that of Geometric Plane
      var left_ear_point_transformed = {"x": left_ear_point.x - nose_point.x, "y": nose_point.y - left_ear_point.y};
      var right_ear_point_transformed = {"x": right_ear_point.x - nose_point.x, "y": nose_point.y - right_ear_point.y};
      
      var point_of_intersection = {"x": 0, "y": 0};
      var slope = 0;

      // Calculating the Slope of the Line
      if(left_ear_point_transformed.x == right_ear_point_transformed.x){
        point_of_intersection.x = left_ear_point_transformed.x;
      }
      else if(left_ear_point_transformed.y == right_ear_point_transformed.y){
        point_of_intersection.y = left_ear_point_transformed.y;
      }
      else{
        slope = (right_ear_point_transformed.y - left_ear_point_transformed.y)/(right_ear_point_transformed.x - left_ear_point_transformed.x);
        point_of_intersection.x = (slope*slope*left_ear_point_transformed.x - slope*left_ear_point_transformed.y)/(1 + slope*slope);
        point_of_intersection.y = left_ear_point_transformed.y + slope*point_of_intersection.x - slope*left_ear_point_transformed.x;
      }
      point_of_intersection.x = point_of_intersection.x + nose_point.x;
      point_of_intersection.y = nose_point.y - point_of_intersection.y;

      // Exit if Tilt is Large
      if(Math.abs(slope)>THRESHOLD_FOR_FACE_TILT){
        ctx.fillStyle = "red";
        ctx.fillText("PLEASE KEEP YOUR FACE STRAIGHT!...",5,20);
        return;
      }

      // Exit if Not Vertically Center
      if(Math.abs((_height/2)-nose_point.y)/(_height/2)>0.1){
        ctx.fillStyle = "red";
        ctx.fillText("Not Vertically Center!...",5,20);
        ctx.fillText("PLEASE KEEP YOUR FACE IN THE CENTER OF SCREEN!...",5,35);
        return;
      }

      // Exit if Not Horizontally Center
      var twv = _width - right_ear_point.x + left_ear_point.x;
      if(Math.abs((twv/2)-left_ear_point.x)/(twv/2)>0.4){
        ctx.fillStyle = "red";
        ctx.fillText("Not Horizondally Center!...",5,20);
        ctx.fillText("PLEASE KEEP YOUR FACE IN THE CENTER OF SCREEN!...",5,35);
        return;
      }
      
      if(VERBOSE == true){
        ctx.fillStyle = "yellow";
        ctx.fillText("Slope: "+slope.toFixed(2),5,65);
        ctx.fillStyle = "green";
        ctx.fillText("Almost Vertically Center!...",5,80);
        ctx.fillStyle = "green";
        ctx.fillText("Almost Horizontally Center!...",5,95);

        // Drawing the Normal Line
        ctx.strokeStyle = "rgb(255,0,0)";
        ctx.beginPath();
        ctx.moveTo(nose_point.x, nose_point.y);
        ctx.lineTo(point_of_intersection.x, point_of_intersection.y);
        ctx.stroke();
      }

      // Calculating the Face Angle For determing which all Earrings to Show
      var distanceBetweenEars = Math.sqrt(Math.pow(left_ear_point.y - right_ear_point.y,2) + Math.pow(left_ear_point.x - right_ear_point.x,2));
      var distanceBetweenLEarAndIntersectionPoint = Math.sqrt(Math.pow(point_of_intersection.y - left_ear_point.y, 2) + Math.pow(point_of_intersection.x - left_ear_point.x, 2));
      var distanceBetweenREarAndIntersectionPoint = Math.sqrt(Math.pow(point_of_intersection.y - right_ear_point.y, 2) + Math.pow(point_of_intersection.x - right_ear_point.x, 2));
      var SepartionDistance = distanceBetweenLEarAndIntersectionPoint - distanceBetweenREarAndIntersectionPoint;
      var DifferencePercentage = "ERROR!...";
      if(distanceBetweenEars > 0){
        DifferencePercentage = SepartionDistance*100/distanceBetweenEars;
        DifferencePercentage = DifferencePercentage.toFixed(2);
      }

      if(VERBOSE == true){
        // Displaying the Face Angle 
        ctx.font = "15px Arial";
        ctx.fillStyle = "yellow";
        ctx.fillText("T-Ear : "+THRESHOLD_FOR_EARING_DETECTION+"%,\t\t\t\tC-Value: "+DifferencePercentage+"%",5,20);
        ctx.fillText("Width : "+_width,5,35);
        ctx.fillText("ED:TW : "+((distanceBetweenEars/_width)*100).toFixed(2),5,50);
      }

      var JewelleryToTry = document.getElementById("JewelleryToTry");
      if(imagetype == "EARRING"){
        OffsetToPlotEar = {"x": 0, "y":0};
        var angle = Math.atan(slope);
        if(left_ear_point.y == right_ear_point.y){
          OffsetToPlotEar.x = THRESHOLD_FOR_EARING_PLACEMENT;
        }
        else if(left_ear_point.x == right_ear_point.x){
          OffsetToPlotEar.y = THRESHOLD_FOR_EARING_PLACEMENT;
        }
        else{
          OffsetToPlotEar.y = Math.sin(angle)*THRESHOLD_FOR_EARING_PLACEMENT;
          OffsetToPlotEar.x = Math.cos(angle)*THRESHOLD_FOR_EARING_PLACEMENT;
        }
        if(DifferencePercentage!="ERROR!..." && Math.abs(DifferencePercentage)>THRESHOLD_FOR_EARING_DETECTION*100){
          if(DifferencePercentage>THRESHOLD_FOR_EARING_DETECTION*100){
            if(VERBOSE == true){
              ctx.fillText("Only Left Earring Visible!...",5,110);
            }
            //Code To Draw Image Here
            ctx.drawImage(JewelleryToTry,left_ear_point.x-25-OffsetToPlotEar.x,left_ear_point.y,50,50);
          }
          else{
            if(VERBOSE == true){
              ctx.fillText("Only Right Earring Visible!...",5,110);
            }
            //Code To Draw Image Here
            ctx.drawImage(JewelleryToTry,right_ear_point.x-25+OffsetToPlotEar.x,right_ear_point.y,50,50);
          }
        }
        else{
          if(VERBOSE == true){
            ctx.fillText("Both Earring Visible!...",5,110);
          }
          //Code To Draw Image Here
          ctx.drawImage(JewelleryToTry,left_ear_point.x-25-OffsetToPlotEar.x,left_ear_point.y,50,50);
          ctx.drawImage(JewelleryToTry,right_ear_point.x-25+OffsetToPlotEar.x,right_ear_point.y,50,50);
        }
      }
      else{
        if(VERBOSE == true){
          ctx.fillStyle = "red";
          ctx.fillText("INVALID IMAGE TYPE",5,110);
        }
      }

      /*if(DifferencePercentage!="ERROR!..." && Math.abs(DifferencePercentage)>THRESHOLD_FOR_EARING*100){
        if(DifferencePercentage>THRESHOLD_FOR_EARING*100){
          ctx.fillText("Value : "+DifferencePercentage+"% Only Left Earring Visible!...",5,20);
        }
        else{
          ctx.fillText("Value : "+DifferencePercentage+"% Only Right Earring Visible!...",5,20);
        }
      }
      else{
        ctx.fillText("Value : "+DifferencePercentage+"% Both Earring Visible!...",5,20);
      }*/

    }
  </script>
</body>
</html>